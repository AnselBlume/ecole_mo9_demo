'''
    Script to evaluate prediction pickles generated by scripts/predict.py.
'''
import os
import sys
sys.path = ['/shared/nas2/blume5/fa23/ecole/src/mo9_demo/src'] + sys.path
import yaml
import json
from tqdm import tqdm
from model.concept import ConceptKB
import jsonargparse
import pickle
import logging, coloredlogs
from scripts.evaluate.metrics import Metric, MetricDict, FlatAccuracy

logger = logging.getLogger(__name__)

def load_concept_kb(config_path: str):
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)

    return ConceptKB.load(config['ckpt_path'])

def predictions_to_json(predictions: list[dict[str, str]]):
    outputs = []
    for prediction in predictions:
        outputs.append({
            'label': prediction['label'],
            'prediction': Metric.extract_predicted_label(prediction['prediction'])
        })

    return outputs

def parse_args(cl_args: list[str] = None, config_str: str = None):
    parser = jsonargparse.ArgumentParser()
    parser.add_argument('--predictions_dir', required=True, type=str, help='Directory containing prediction pickles')
    parser.add_argument('--output_path', required=True, type=str, help='Path to save evaluation results')

    parser.add_argument('--evaluation.exclude_parts', type=bool, default=True, help='Whether to exclude parts from evaluation')

    if config_str:
        args = parser.parse_string(config_str)
    else:
        args = parser.parse_args(cl_args)

    return args, parser

def main(args: jsonargparse.Namespace, parser: jsonargparse.ArgumentParser):
    predictions_pkl_path = os.path.join(args.predictions_dir, 'predictions.pkl')
    config_path = os.path.join(args.predictions_dir, 'args.yaml')

    # Load ConceptKB for graph
    concept_kb = load_concept_kb(config_path)
    part_names = [c.name for c in concept_kb.component_concepts]

    # Load predictions
    with open(predictions_pkl_path, 'rb') as f:
        predictions = pickle.load(f)

    # Compute metrics
    metrics = MetricDict({
        'accuracy_flat': FlatAccuracy()
    })

    filtered_predictions = []
    for prediction in tqdm(predictions):
        if args.evaluation.exclude_parts:
            if prediction['label'] in part_names:
                continue

        metrics(prediction)
        filtered_predictions.append(prediction)

    # Write results
    results = metrics.compute()
    with open(args.output_path, 'w') as f:
        yaml.dump(results, f)

    # Write predictions to json
    predictions_json = predictions_to_json(filtered_predictions)
    predictions_json_path = os.path.join(args.predictions_dir, 'predictions.json')
    with open(predictions_json_path, 'w') as f:
        json.dump(predictions_json, f, indent=4)

    logger.info('Done')

if __name__ == '__main__':
    coloredlogs.install(level='DEBUG')

    args, parser = parse_args(config_str='''
        # predictions_dir: /shared/nas2/blume5/fa23/ecole/test_images_predictions
        # output_path: /shared/nas2/blume5/fa23/ecole/test_images_predictions/results.yaml

        predictions_dir: /shared/nas2/blume5/fa23/ecole/test_gt_region_predictions
        output_path: /shared/nas2/blume5/fa23/ecole/test_gt_region_predictions/no_parts_results.yaml

        evaluation:
            exclude_parts: true
    ''')

    main(args, parser)